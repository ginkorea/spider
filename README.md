# ğŸ•·ï¸ go-spider

**go-spider** is an LLM-driven, goal-oriented web crawler designed for autonomous information discovery.  
It combines browser-based rendering, intelligent link prioritization, and language-model reasoning to search the web until it achieves a defined goal â€” not just until it runs out of links.

---

## ğŸš€ Key Features

- **ğŸ¯ Goal-Oriented Crawling** â€“ Specify a goal or question (e.g. â€œFind this companyâ€™s investor relations contactâ€) and let go-spider autonomously explore until it finds a confident answer.
- **ğŸ§  LLM-Powered Relevance Ranking** â€“ Uses a local or cloud-based LLM to score link and content relevance dynamically.
- **ğŸ•µï¸ Stealth Mode (Optional)** â€“ Integrates with VPNs for geo-specific or anonymized browsing.
- **ğŸ“š Persistent Memory** â€“ Optionally logs pages and embeddings for later retrieval-augmented generation (RAG) search.
- **ğŸŒ Playwright Rendering** â€“ Fetches fully rendered pages (JS, AJAX, etc.) to ensure accurate content capture.
- **âš™ï¸ Modular Architecture** â€“ Swap in your own LLM client, browser backend, or vector DB.

---

## ğŸ§© Installation

Install directly from PyPI:

```bash
pip install go-spider
````

To run locally with development dependencies:

```bash
git clone https://github.com/YOUR_GITHUB_USERNAME/go-spider.git
cd go-spider
pip install -e .
```

---

## ğŸ•¹ï¸ Basic Usage

### Crawl a single site

```bash
spider "https://example.com"
```

### Goal-Oriented Crawl

```bash
spider "https://example.com" \
  --goal "Find this site's investor relations email" \
  --max-pages 25 \
  --confidence 0.9
```

Example output:

```
[CLI] ğŸš€ Running Goal Spider for goal: 'Find this site's investor relations email'
[BasicSpider] INFO Rendering URL: https://example.com
[BasicSpider] INFO Rendering URL: https://iana.org/domains/example
[BasicSpider] INFO Rendering URL: https://iana.org/contact

=== GOAL RESULT ===
Goal: Find this site's investor relations email
Confidence: 1.00
Visited pages: 3
Answer:
No contact email found.
The page does not provide a direct contact email, but includes: iana@iana.org
===================
```

---

## âš™ï¸ Command-Line Options

| Flag            | Description                                    |
| --------------- | ---------------------------------------------- |
| `--goal`        | Question or target objective for the crawl     |
| `--stealth`     | Use VPN-protected stealth browsing             |
| `--region`      | VPN region (e.g. `hong_kong`)                  |
| `--db`          | SQLite database path for persistent crawl logs |
| `--max-pages`   | Maximum number of pages to visit               |
| `--confidence`  | Confidence threshold to stop searching         |
| `--pretty`      | Pretty-print output JSON                       |
| `--no-headless` | Run Playwright browser visibly                 |
| `--output`      | Output path (default: `output.jsonl`)          |

---

## ğŸ§  Architecture Overview

```text
PlaywrightBrowserClient  â†’  BasicSpider / StealthSpider / GoalSpider
                                    â†“
                         RelevanceRanker (LLM-based)
                                    â†“
                               TextChunker
                                    â†“
                              Goal Planner
                                    â†“
                             SQLite + Embeddings
```

* **BasicSpider** â€“ standard site fetcher
* **StealthSpider** â€“ uses VPN-enforced browsing
* **GoalSpider** â€“ iterative goal-driven crawler (core of go-spider)

---

## ğŸ§© Integration Example (Python API)

You can also use it as a library:

```python
from spider_core.spiders.goal_spider import GoalSpider
from spider_core.browser.playwright_client import PlaywrightBrowserClient
from spider_core.llm.openai_gpt_client import OpenAIGPTClient
from spider_core.llm.relevance_ranker import RelevanceRanker
from spider_core.core_utils.chunking import TextChunker
import asyncio

async def main():
    browser = PlaywrightBrowserClient()
    llm = OpenAIGPTClient()
    ranker = RelevanceRanker(llm)
    chunker = TextChunker()

    spider = GoalSpider(browser_client=browser, relevance_ranker=ranker, chunker=chunker, llm_client=llm)
    result = await spider.run_goal("https://example.com", "Find contact email")
    print(result)

asyncio.run(main())
```

---

## ğŸ§° Requirements

* Python 3.10+
* Playwright
* OpenAI-compatible LLM API key (optional)
* Works on Linux, macOS, and Windows (with Playwright browsers installed)

---

## ğŸ—ï¸ Roadmap

* [ ] Add distributed crawling support
* [ ] Integrate local LLMs via `llama.cpp`
* [ ] Add vector DB backends (FAISS / Chroma / SQLite-VSS)
* [ ] Fine-grained crawl policies (robots.txt, depth weighting)
* [ ] RAG API for querying past crawls

---

## ğŸ§‘â€ğŸ’» Author

**Josh Gompert**
AI Systems Engineer â€¢ Data Scientist â€¢ Information Operations Officer

* GitHub: [@ginkorea](https://github.com/ginkorea)
* PyPI: [go-spider](https://pypi.org/project/go-spider/)

---

## ğŸªª License

**MIT License** â€” free to use, modify, and distribute.
See `LICENSE` file for details.

---

> *â€œgo-spider doesnâ€™t just crawl the web â€” it pursues intent.â€*
